
# 微信AI助手机器人

一个基于Python的微信AI助手机器人，支持本地AI模式（Ollama）和云端AI模式（OpenAI），可以自动回复群聊和私聊消息。

## 🔍 项目原理

### 消息监听机制
- 使用wxauto库监听微信PC版的消息事件
- 通过Windows消息钩子实现实时消息捕获
- 支持群聊@消息和私聊消息的自动识别

### AI接口调用
- 双模式支持：
  - 本地模式：通过HTTP请求调用Ollama API
  - 云端模式：调用OpenAI API接口
- 异步处理机制，避免消息处理阻塞

### 消息处理流程
1. 接收并解析微信消息
2. 根据配置过滤不需要处理的消息
3. 调用相应的AI接口生成回复
4. 通过wxauto发送回复消息

## ✨ 功能特点

- 🤖 双模式支持：可选择本地AI（Ollama）或云端AI（OpenAI）
- 🎯 智能消息处理：自动识别并回复@消息
- 🎨 图形化配置界面：简单易用的设置界面
- 🔧 灵活的配置选项：支持自定义API地址、模型名称等
- 🎭 角色定制：支持自定义AI助手的角色设定和行为模式
- ⚡ 实时响应：快速处理群聊和私聊消息

## 🚀 使用指南

### 1. 环境准备

- 安装Python 3.7+
- 安装微信PC版（请使用最新版本）
- 确保系统为Windows（由于使用了Windows API）

### 2. 安装步骤

1. 下载项目文件
2. 安装依赖包：
   ```bash
   pip install wxauto openai requests PyQt5
   ```
3. 如果使用本地AI模式，需要安装并启动Ollama

### 3. 配置说明

#### 本地AI模式（Ollama）
- API地址：默认为 `http://127.0.0.1:11434/api/chat`
- 模型名称：选择已安装的Ollama模型
- 机器人名称：设置机器人的昵称

#### 云端AI模式（OpenAI）
- API密钥：填入OpenAI的API Key
- API地址：可使用官方或第三方地址
- 模型名称：如 `gpt-3.5-turbo`

### 4. 启动使用

1. 运行图形界面程序：
   ```bash
   python main.py
   ```
2. 在界面中选择运行模式并完成配置
3. 点击"启动机器人"开始运行
4. 在需要机器人回复的消息中@机器人即可

## 💡 使用建议

### 性能优化
1. 本地模式建议使用较小的模型以提高响应速度
2. 适当设置消息过滤规则，避免处理不必要的消息
3. 定期清理日志文件以节省存储空间

### 安全注意事项
1. 请勿在公共场合泄露API密钥
2. 建议使用代理API地址以保护隐私
3. 定期检查并更新依赖包版本

### 最佳实践
1. 为机器人设置合适的角色定位和行为模式
2. 在重要群聊中先进行测试再正式使用
3. 定期备份配置文件

## 📝 配置文件说明

配置文件 `config.json` 包含以下主要设置：

- `ignoreFriends`：需要忽略的好友列表
- `ignoreMessages`：需要忽略的消息类型
- `system_prompt`：AI助手的角色设定

## ❓ 常见问题

1. **机器人无法接收消息？**
   - 确保微信已登录并保持在线
   - 检查是否正确@机器人
   - 验证微信窗口是否被其他窗口遮挡

2. **Ollama模式无法连接？**
   - 确保Ollama服务已启动
   - 检查API地址是否正确
   - 验证防火墙设置

3. **消息发送失败？**
   - 检查网络连接
   - 确保微信窗口未被最小化
   - 验证是否有足够的发送权限

## 🤝 贡献

欢迎提交Issue和Pull Request来帮助改进项目！

## 📜 许可证

本项目采用MIT许可证

